{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6916830b",
   "metadata": {},
   "source": [
    "### Setting environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04023432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system environment variables\n",
    "import os\n",
    "\n",
    "# Set the LANGCHAIN_TRACING_V2 environment variable to enable tracing for LangChain version 2\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "\n",
    "# Set the LANGCHAIN_PROJECT environment variable to specify the project name in LangChain\n",
    "#os.environ['LANGCHAIN_PROJECT'] = \"agentic-workflow\"\n",
    "\n",
    "# Set the LANGSMITH_USER_HANDLE environment variable with your LangSmith user handle\n",
    "#os.environ['LANGSMITH_USER_HANDLE'] = \"hrisi-learn\"\n",
    "\n",
    "# Set the SERPAPI_API_KEY environment variable with your SERP API key\n",
    "#os.environ['SERPAPI_API_KEY'] = \"\"\n",
    "\n",
    "# Set Azure OpenAI API key\n",
    "#os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "#os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"] = \"\"\n",
    "#os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22564650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class from the langsmith module to create a client instance\n",
    "from langsmith import Client\n",
    "\n",
    "# Initialize a new client instance using the Client class\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92085946",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356fbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the itemgetter function from the operator module to extract items from objects\n",
    "from operator import itemgetter\n",
    "\n",
    "# Import the hub module from langchain to access its functionalities\n",
    "from langchain import hub\n",
    "\n",
    "# Import the AgentExecutor class from langchain.agents to execute agent actions\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Import the load_tools function from langchain.agents to load necessary tools for agents\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "# Import the format_to_openai_functions function from langchain.agents.format_scratchpad\n",
    "# to convert scratchpad content into OpenAI functions\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "\n",
    "# Import the OpenAIFunctionsAgentOutputParser class from langchain.agents.output_parsers\n",
    "# to parse the output of agents into OpenAI functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "# Import the ChatOpenAI class from langchain.chat_models to interact with OpenAI chat models\n",
    "from langchain.chat_models import ChatOpenAI,AzureChatOpenAI\n",
    "\n",
    "# Import the format_tool_to_openai_function function from langchain.tools.render\n",
    "# to format tools into OpenAI functions\n",
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ca7aa5-3eb7-42e9-9b1b-05d9a51f97f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.8.6-cp38-cp38-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\python38\\lib\\site-packages (from numexpr) (1.24.4)\n",
      "Downloading numexpr-2.8.6-cp38-cp38-win_amd64.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/95.0 kB ? eta -:--:--\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 92.2/95.0 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 95.0/95.0 kB 285.2 kB/s eta 0:00:00\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.8.6\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232b9e5",
   "metadata": {},
   "source": [
    "### Initializing LLMs and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea8db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python38\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\program files\\python38\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the ChatOpenAI class to interact with OpenAI's chat models\n",
    "#llm = ChatOpenAI()\n",
    "llm = AzureChatOpenAI(model=\"hrisikesh-gpt-35-turbo\", temperature=0,api_version=\"2024-02-01\")\n",
    "# Load tools such as serpapi, wikipedia, and llm-math using the load_tools function\n",
    "tools = load_tools([\"serpapi\", \"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Bind the loaded tools to the language model (llm) by converting them into OpenAI functions\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa106d68",
   "metadata": {},
   "source": [
    "### Prompt design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44fc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the hub.pull method from the langchain hub to retrieve a specific prompt\n",
    "prompt = hub.pull(\"wfh/agent-lcel-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db10f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function named format_scratchpad that takes a dictionary as input\n",
    "# The dictionary is expected to contain a key \"intermediate_steps\" whose value is processed\n",
    "# using the format_to_openai_functions function to convert intermediate steps into a string\n",
    "def format_scratchpad(x: dict) -> str:\n",
    "    return format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "\n",
    "# Define a function named get_chat_history that takes a list as input\n",
    "# The list is expected to contain a dictionary with a key \"chat_history\"\n",
    "# If the \"chat_history\" key exists, its value is returned; otherwise, an empty list is returned\n",
    "def get_chat_history(x: list) -> str:\n",
    "    return x.get(\"chat_history\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba6a1d",
   "metadata": {},
   "source": [
    "### Creating agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3ccd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an agent configuration dictionary with specific functions mapped to keys\n",
    "# \"input\" is mapped to the itemgetter function to extract the \"input\" field from a given object\n",
    "# \"agent_scratchpad\" is mapped to the format_scratchpad function to process intermediate steps\n",
    "# \"chat_history\" is mapped to the get_chat_history function to retrieve chat history\n",
    "agent_config = {\n",
    "    \"input\": itemgetter(\"input\"),  # Map \"input\" to the itemgetter function\n",
    "    \"agent_scratchpad\": format_scratchpad,  # Map \"agent_scratchpad\" to the format_scratchpad function\n",
    "    \"chat_history\": get_chat_history  # Map \"chat_history\" to the get_chat_history function\n",
    "}\n",
    "\n",
    "# Apply the agent configuration to a prompt using the pipe operator\n",
    "# This involves pulling the prompt from the hub, binding it with the loaded tools (llm_with_tools),\n",
    "# and then processing it through the agent configuration\n",
    "# The result is then parsed by the OpenAIFunctionsAgentOutputParser to format the output\n",
    "agent = (\n",
    "    agent_config\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72efca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an AgentExecutor object with the specified agent configuration and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7146d69",
   "metadata": {},
   "source": [
    "### Questions to agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c5b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"who is Indian prime minister\",\n",
    "          \"What is US President's age and return the number age multiplied by two\",\n",
    "          \"what is the name of OpenAI's new AI model?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625bea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm sorry, but I cannot answer that question without additional information. Which US President are you referring to?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = agent_executor.batch([{\"input\": x} for x in inputs], return_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44160762-215a-4cd1-8f05-9acc90f5cf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ValueError('An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse tool input: {\\'arguments\\': \"const wikipedia = require(\\'wikipedia\\');\\\\n\\\\nasync function indianPrimeMinister() {\\\\n  const page = await wikipedia.page(\\'Prime Minister of India\\');\\\\n  const summary = await page.summary();\\\\n  const intro = summary.intro;\\\\n  const regex = /([A-Z][a-z]+ ){1,2}(Modi|Singh|Gandhi)/;\\\\n  const match = intro.match(regex);\\\\n  return match[0];\\\\n}\\\\n\\\\nindianPrimeMinister();\", \\'name\\': \\'functions\\'} because the `arguments` is not valid JSON.'),\n",
       " {'input': \"What is US President's age and return the number age multiplied by two\",\n",
       "  'output': \"I'm sorry, but I cannot answer that question without additional information. Which US President are you referring to?\"},\n",
       " ValueError('An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse tool input: {\\'arguments\\': \\'const search: functions.Search = async ({ __arg1 }) => {\\\\n  const searchUrl = `https://www.google.com/search?q=${encodeURIComponent(__arg1)}`;\\\\n  const response = await fetch(searchUrl);\\\\n  const text = await response.text();\\\\n  const match = text.match(/<div class=\"BNeawe iBp4i AP7Wnd\">(.*?)<\\\\\\\\/div>/);\\\\n  if (match) {\\\\n    return match[1];\\\\n  } else {\\\\n    throw new Error(`No results found for \"${__arg1}\"`);\\\\n  }\\\\n};\\\\n\\\\nsearch({ __arg1: \"OpenAI\\\\\\'s new AI model name\" }).then(console.log).catch(console.error);\\', \\'name\\': \\'functions\\'} because the `arguments` is not valid JSON.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a10a1-38bf-4dd8-8936-47f99483202f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
